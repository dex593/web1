#!/usr/bin/env node
"use strict";

const path = require("path");
const fs = require("fs");
const sqlite3 = require("sqlite3").verbose();
const { Pool, types } = require("pg");

types.setTypeParser(20, (value) => (value == null ? null : Number.parseInt(value, 10))); // int8
types.setTypeParser(1700, (value) => (value == null ? null : Number.parseFloat(value))); // numeric

const DEFAULT_PG_URL = (process.env.DATABASE_URL || "").toString().trim();

const parseArgs = (argv) => {
  const result = {
    sqlitePath: path.join(__dirname, "..", "data", "bfang.db"),
    pgUrl: DEFAULT_PG_URL
  };

  for (let i = 0; i < argv.length; i += 1) {
    const arg = argv[i];
    if (arg === "--sqlite" && argv[i + 1]) {
      result.sqlitePath = argv[i + 1];
      i += 1;
      continue;
    }
    if (arg === "--pg" && argv[i + 1]) {
      result.pgUrl = argv[i + 1];
      i += 1;
      continue;
    }
    if (arg === "--help" || arg === "-h") {
      result.help = true;
    }
  }

  return result;
};

const openSqlite = (sqlitePath) =>
  new Promise((resolve, reject) => {
    const db = new sqlite3.Database(sqlitePath, (err) => {
      if (err) return reject(err);
      return resolve(db);
    });
  });

const sqliteAll = (db, sql, params = []) =>
  new Promise((resolve, reject) => {
    db.all(sql, params, (err, rows) => {
      if (err) return reject(err);
      return resolve(rows || []);
    });
  });

const closeSqlite = (db) =>
  new Promise((resolve, reject) => {
    db.close((err) => {
      if (err) return reject(err);
      return resolve();
    });
  });

const nullify = (value) => (value == null ? null : value);

const ensurePgSchema = async (client) => {
  await client.query(
    `
    CREATE TABLE IF NOT EXISTS manga (
      id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      title TEXT NOT NULL,
      slug TEXT NOT NULL UNIQUE,
      author TEXT NOT NULL,
      genres TEXT,
      status TEXT,
      description TEXT,
      cover TEXT,
      archive TEXT,
      updated_at TEXT NOT NULL,
      created_at TEXT NOT NULL,
      is_hidden INTEGER NOT NULL DEFAULT 0,
      group_name TEXT,
      other_names TEXT,
      cover_updated_at BIGINT
    )
  `
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS chapters (
      id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      manga_id INTEGER NOT NULL REFERENCES manga(id) ON DELETE CASCADE,
      number NUMERIC(10, 3) NOT NULL,
      title TEXT NOT NULL,
      pages INTEGER NOT NULL,
      date TEXT NOT NULL,
      group_name TEXT,
      pages_prefix TEXT,
      pages_ext TEXT,
      pages_updated_at BIGINT,
      processing_state TEXT,
      processing_error TEXT,
      processing_draft_token TEXT,
      processing_pages_json TEXT,
      processing_updated_at BIGINT
    )
  `
  );
  await client.query(
    "CREATE UNIQUE INDEX IF NOT EXISTS idx_chapters_manga_number ON chapters (manga_id, number)"
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS chapter_drafts (
      token TEXT PRIMARY KEY,
      manga_id INTEGER NOT NULL REFERENCES manga(id) ON DELETE CASCADE,
      pages_prefix TEXT NOT NULL,
      created_at BIGINT NOT NULL,
      updated_at BIGINT NOT NULL
    )
  `
  );
  await client.query(
    "CREATE INDEX IF NOT EXISTS idx_chapter_drafts_updated_at ON chapter_drafts(updated_at)"
  );
  await client.query(
    "CREATE INDEX IF NOT EXISTS idx_chapter_drafts_manga_id ON chapter_drafts(manga_id)"
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS comments (
      id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      manga_id INTEGER NOT NULL REFERENCES manga(id) ON DELETE CASCADE,
      chapter_number NUMERIC(10, 3),
      parent_id INTEGER,
      author TEXT NOT NULL,
      content TEXT NOT NULL,
      status TEXT NOT NULL DEFAULT 'visible',
      like_count INTEGER NOT NULL DEFAULT 0,
      report_count INTEGER NOT NULL DEFAULT 0,
      created_at TEXT NOT NULL
    )
  `
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS homepage (
      id INTEGER PRIMARY KEY CHECK (id = 1),
      notice_title_1 TEXT,
      notice_body_1 TEXT,
      notice_title_2 TEXT,
      notice_body_2 TEXT,
      featured_ids TEXT,
      updated_at TEXT NOT NULL
    )
  `
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS genres (
      id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      name TEXT NOT NULL
    )
  `
  );
  await client.query(
    "CREATE UNIQUE INDEX IF NOT EXISTS idx_genres_name_lower ON genres ((lower(name)))"
  );

  await client.query(
    `
    CREATE TABLE IF NOT EXISTS manga_genres (
      manga_id INTEGER NOT NULL REFERENCES manga(id) ON DELETE CASCADE,
      genre_id INTEGER NOT NULL REFERENCES genres(id) ON DELETE CASCADE,
      PRIMARY KEY (manga_id, genre_id)
    )
  `
  );
  await client.query(
    "CREATE INDEX IF NOT EXISTS idx_manga_genres_genre_id ON manga_genres(genre_id)"
  );
  await client.query(
    "CREATE INDEX IF NOT EXISTS idx_manga_genres_manga_id ON manga_genres(manga_id)"
  );
};

const setIdentityToMax = async (client, table, column) => {
  const safeTable = String(table);
  const safeColumn = String(column);
  const sql = `
    SELECT setval(
      pg_get_serial_sequence('${safeTable}', '${safeColumn}'),
      COALESCE((SELECT MAX(${safeColumn}) FROM ${safeTable}), 1),
      true
    ) as ok
  `;
  await client.query(sql);
};

const main = async () => {
  const args = parseArgs(process.argv.slice(2));
  if (args.help) {
    console.log("Usage: node scripts/migrate-sqlite-to-postgres.js [--sqlite <path>] [--pg <postgresql://...>]");
    process.exit(0);
  }

  const sqlitePath = path.resolve(args.sqlitePath);
  if (!fs.existsSync(sqlitePath)) {
    console.error(`SQLite DB not found: ${sqlitePath}`);
    process.exit(1);
  }

  if (!args.pgUrl) {
    console.error("Missing PostgreSQL URL. Set DATABASE_URL in .env or pass --pg <postgresql://...>");
    process.exit(1);
  }

  const sqliteDb = await openSqlite(sqlitePath);
  const pgPool = new Pool({ connectionString: args.pgUrl });
  const pgClient = await pgPool.connect();

  try {
    await pgClient.query("BEGIN");
    await ensurePgSchema(pgClient);

    const pgCount = await pgClient
      .query("SELECT COUNT(*) as count FROM manga")
      .then((res) => (res.rows && res.rows[0] ? Number(res.rows[0].count) : 0));
    if (pgCount > 0) {
      throw new Error(
        "PostgreSQL database already has data in manga table. Please migrate into an empty DB (or drop/truncate tables first)."
      );
    }

    const mangaRows = await sqliteAll(sqliteDb, "SELECT * FROM manga ORDER BY id ASC");
    const genreRows = await sqliteAll(sqliteDb, "SELECT * FROM genres ORDER BY id ASC");
    const mangaGenreRows = await sqliteAll(
      sqliteDb,
      "SELECT * FROM manga_genres ORDER BY manga_id ASC, genre_id ASC"
    );
    const chapterRows = await sqliteAll(sqliteDb, "SELECT * FROM chapters ORDER BY id ASC");
    const commentRows = await sqliteAll(sqliteDb, "SELECT * FROM comments ORDER BY id ASC");
    const homepageRows = await sqliteAll(sqliteDb, "SELECT * FROM homepage ORDER BY id ASC");
    const draftRows = await sqliteAll(sqliteDb, "SELECT * FROM chapter_drafts ORDER BY updated_at ASC");

    for (const row of mangaRows) {
      await pgClient.query(
        `
        INSERT INTO manga (
          id, title, slug, author, genres, status, description, cover, archive,
          updated_at, created_at, is_hidden, group_name, other_names, cover_updated_at
        )
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
      `,
        [
          row.id,
          row.title,
          row.slug,
          row.author,
          nullify(row.genres),
          nullify(row.status),
          nullify(row.description),
          nullify(row.cover),
          nullify(row.archive),
          row.updated_at,
          row.created_at,
          row.is_hidden == null ? 0 : row.is_hidden,
          nullify(row.group_name),
          nullify(row.other_names),
          nullify(row.cover_updated_at)
        ]
      );
    }

    for (const row of genreRows) {
      await pgClient.query(
        "INSERT INTO genres (id, name) VALUES ($1, $2)",
        [row.id, row.name]
      );
    }

    for (const row of mangaGenreRows) {
      await pgClient.query(
        "INSERT INTO manga_genres (manga_id, genre_id) VALUES ($1, $2) ON CONFLICT DO NOTHING",
        [row.manga_id, row.genre_id]
      );
    }

    for (const row of chapterRows) {
      await pgClient.query(
        `
        INSERT INTO chapters (
          id, manga_id, number, title, pages, date, group_name,
          pages_prefix, pages_ext, pages_updated_at,
          processing_state, processing_error, processing_draft_token,
          processing_pages_json, processing_updated_at
        )
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
      `,
        [
          row.id,
          row.manga_id,
          row.number,
          row.title,
          row.pages,
          row.date,
          nullify(row.group_name),
          nullify(row.pages_prefix),
          nullify(row.pages_ext),
          nullify(row.pages_updated_at),
          nullify(row.processing_state),
          nullify(row.processing_error),
          nullify(row.processing_draft_token),
          nullify(row.processing_pages_json),
          nullify(row.processing_updated_at)
        ]
      );
    }

    for (const row of commentRows) {
      await pgClient.query(
        `
        INSERT INTO comments (
          id, manga_id, chapter_number, parent_id, author, content,
          status, like_count, report_count, created_at
        )
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
      `,
        [
          row.id,
          row.manga_id,
          nullify(row.chapter_number),
          nullify(row.parent_id),
          row.author,
          row.content,
          (row.status || "visible").toString(),
          row.like_count == null ? 0 : row.like_count,
          row.report_count == null ? 0 : row.report_count,
          row.created_at
        ]
      );
    }

    for (const row of homepageRows) {
      const updatedAt = row.updated_at || new Date().toISOString();
      await pgClient.query(
        `
        INSERT INTO homepage (
          id, notice_title_1, notice_body_1, notice_title_2, notice_body_2, featured_ids, updated_at
        )
        VALUES ($1, $2, $3, $4, $5, $6, $7)
        ON CONFLICT (id) DO UPDATE
        SET
          notice_title_1 = EXCLUDED.notice_title_1,
          notice_body_1 = EXCLUDED.notice_body_1,
          notice_title_2 = EXCLUDED.notice_title_2,
          notice_body_2 = EXCLUDED.notice_body_2,
          featured_ids = EXCLUDED.featured_ids,
          updated_at = EXCLUDED.updated_at
      `,
        [
          row.id,
          nullify(row.notice_title_1),
          nullify(row.notice_body_1),
          nullify(row.notice_title_2),
          nullify(row.notice_body_2),
          nullify(row.featured_ids),
          updatedAt
        ]
      );
    }

    for (const row of draftRows) {
      await pgClient.query(
        `
        INSERT INTO chapter_drafts (token, manga_id, pages_prefix, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5)
        ON CONFLICT (token) DO NOTHING
      `,
        [row.token, row.manga_id, row.pages_prefix, row.created_at, row.updated_at]
      );
    }

    await setIdentityToMax(pgClient, "manga", "id");
    await setIdentityToMax(pgClient, "genres", "id");
    await setIdentityToMax(pgClient, "chapters", "id");
    await setIdentityToMax(pgClient, "comments", "id");

    await pgClient.query("COMMIT");
    console.log("Migration completed successfully.");
    console.log(`SQLite: ${sqlitePath}`);
    console.log(`Postgres: ${args.pgUrl}`);
  } catch (err) {
    try {
      await pgClient.query("ROLLBACK");
    } catch (_rollbackErr) {
      // ignore
    }
    console.error("Migration failed:");
    console.error(err && err.stack ? err.stack : err);
    process.exitCode = 1;
  } finally {
    pgClient.release();
    await pgPool.end().catch(() => null);
    await closeSqlite(sqliteDb).catch(() => null);
  }
};

main();
